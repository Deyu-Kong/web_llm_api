# test_openai.py
"""
æµ‹è¯• OpenAI å…¼å®¹ API
ä½¿ç”¨å®˜æ–¹ OpenAI Python SDK è¿›è¡Œè°ƒç”¨
"""

from openai import OpenAI

# é…ç½®å®¢æˆ·ç«¯
client = OpenAI(
    base_url="http://127.0.0.1:8000/v1",
    api_key="not-needed"  # æœ¬åœ°æœåŠ¡ä¸éœ€è¦çœŸå®çš„ API key
)

def test_list_models():
    """æµ‹è¯•è·å–æ¨¡å‹åˆ—è¡¨"""
    print("=" * 50)
    print("æµ‹è¯• 1: è·å–æ¨¡å‹åˆ—è¡¨")
    print("=" * 50)
    
    try:
        models = client.models.list()
        print("å¯ç”¨æ¨¡å‹:")
        for model in models.data:
            print(f"  - {model.id} (owned by: {model.owned_by})")
        return True
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        return False

def test_kimi():
    """æµ‹è¯• Kimi æ¨¡å‹"""
    print("\n" + "=" * 50)
    print("æµ‹è¯• 2: Kimi æ¨¡å‹")
    print("=" * 50)
    
    try:
        response = client.chat.completions.create(
            model="kimi",
            messages=[
                {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±"}
            ]
        )
        
        print(f"æ¨¡å‹: {response.model}")
        print(f"å›å¤: {response.choices[0].message.content}")
        print(f"Token ä½¿ç”¨: {response.usage.total_tokens}")
        return True
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        return False

def test_lmarena_default():
    """æµ‹è¯• LMArena é»˜è®¤æ¨¡å‹"""
    print("\n" + "=" * 50)
    print("æµ‹è¯• 3: LMArena é»˜è®¤æ¨¡å‹")
    print("=" * 50)
    
    try:
        response = client.chat.completions.create(
            model="lmarena",
            messages=[
                {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±"}
            ]
        )
        
        print(f"æ¨¡å‹: {response.model}")
        print(f"å›å¤: {response.choices[0].message.content}")
        print(f"Token ä½¿ç”¨: {response.usage.total_tokens}")
        return True
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        return False

def test_lmarena_specific_model(model_name: str = "claude-opus-4-5-20251101-thinking-32k"):
    """æµ‹è¯• LMArena æŒ‡å®šæ¨¡å‹"""
    print("\n" + "=" * 50)
    print(f"æµ‹è¯• 4: LMArena æŒ‡å®šæ¨¡å‹ ({model_name})")
    print("=" * 50)
    
    try:
        response = client.chat.completions.create(
            model=f"lmarena:{model_name}",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹"},
                {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±"}
            ]
        )
        
        print(f"æ¨¡å‹: {response.model}")
        print(f"å›å¤: {response.choices[0].message.content}")
        print(f"Token ä½¿ç”¨: {response.usage.total_tokens}")
        return True
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        return False

def test_multi_turn_conversation():
    """æµ‹è¯•å¤šè½®å¯¹è¯ï¼ˆæ³¨æ„ï¼šå½“å‰å®ç°æ¯æ¬¡éƒ½æ˜¯æ–°å¯¹è¯ï¼‰"""
    print("\n" + "=" * 50)
    print("æµ‹è¯• 5: å¤šè½®å¯¹è¯æ ¼å¼")
    print("=" * 50)
    
    try:
        response = client.chat.completions.create(
            model="lmarena",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ•°å­¦è€å¸ˆ"},
                {"role": "user", "content": "1+1ç­‰äºå¤šå°‘ï¼Ÿ"},
                {"role": "assistant", "content": "1+1=2"},
                {"role": "user", "content": "é‚£å†åŠ 1å‘¢ï¼Ÿ"}
            ]
        )
        
        print(f"æ¨¡å‹: {response.model}")
        print(f"å›å¤: {response.choices[0].message.content}")
        return True
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        return False

def interactive_chat():
    """äº¤äº’å¼å¯¹è¯"""
    print("\n" + "=" * 50)
    print("äº¤äº’å¼å¯¹è¯æ¨¡å¼")
    print("è¾“å…¥ 'quit' é€€å‡º, 'model:xxx' åˆ‡æ¢æ¨¡å‹")
    print("=" * 50)
    
    current_model = "lmarena"
    
    while True:
        user_input = input(f"\n[{current_model}] ä½ : ").strip()
        
        if user_input.lower() == 'quit':
            print("å†è§ï¼")
            break
        
        if user_input.lower().startswith('model:'):
            current_model = user_input[6:].strip()
            print(f"å·²åˆ‡æ¢åˆ°æ¨¡å‹: {current_model}")
            continue
        
        if not user_input:
            continue
        
        try:
            response = client.chat.completions.create(
                model=current_model,
                messages=[{"role": "user", "content": user_input}]
            )
            print(f"\nåŠ©æ‰‹: {response.choices[0].message.content}")
        except Exception as e:
            print(f"\né”™è¯¯: {e}")

if __name__ == "__main__":
    print("\nğŸ§ª å¼€å§‹æµ‹è¯• OpenAI å…¼å®¹ API\n")
    
    # è¿è¡Œæµ‹è¯•
    test_list_models()
    
    # å¯ä»¥é€‰æ‹©æ€§è¿è¡Œä»¥ä¸‹æµ‹è¯•
    # test_kimi()
    test_lmarena_default()
    # test_lmarena_specific_model()
    # test_multi_turn_conversation()
    
    # äº¤äº’å¼å¯¹è¯
    # interactive_chat()
    
    print("\nâœ… æµ‹è¯•å®Œæˆ!")